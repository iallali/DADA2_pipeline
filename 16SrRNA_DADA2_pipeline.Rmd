---
title: "16S rRNA pipeline using DADA2"
author: 'Instructors: Imane Allali'
---

<br/><br/>
 
## <span style="color:green">The dataset</span>
The dataset we will be working are the practice dataset from the [H3ABioNet 16S rDNA diversity analysis SOP](https://h3abionet.github.io/H3ABionet-SOPs/16s-rRNA-1-0.html). The source data can be accessed [here](http://h3data.cbio.uct.ac.za/assessments/16SrRNADiversityAnalysis/practice) but for our purposes it is already on the cluster.

The table below contains the metadata associated with the dog stool samples. There are three dogs which are treated with increased percentage of a compound in their diet: 5 different treatments (0-4, representing an increased percentage of a compound in their diet).


| Sample  | Dog    | Treatment  | Read Counts r1  | Read Counts r2 |
| :-------| :----: | :--------: | :-------------: | ----------:    | 
|  Dog1   | B      | 2          |  118343         | 118343         |
|  Dog2   | G      | 3          |  108679	        | 108679         | 
|  Dog3   | K      | 3          |  101482         | 101482         | 
|  Dog8   | B      | 4          |  108731         | 108731         | 
|  Dog9   | G      | 0          |  109500         | 109500         | 
|  Dog10  | K      | 4          |  79342          | 79342          | 
|  Dog15  | B      | 1          |  131483         | 131483         | 
|  Dog16  | G      | 4          |  114424         | 114424         | 
|  Dog17  | K      | 0          |  99610	        | 99610	         | 
|  Dog22  | B      | 3          |  145029         | 145029         | 
|  Dog23  | G      | 1          |  193158         | 193158         | 
|  Dog24  | K      | 2          |  162487         | 162487         | 
|  Dog29  | B      | 0          |  122776         | 122776         | 
|  Dog30  | G      | 2          |  137315         | 137315         | 
|  Dog31  | K      | 1          |  150613         | 150613         | 

<br/><br/>

## <span style="color:green">Getting Ready</span>
First, we load the <span style="color:blue">dada2</span> package on your RStudio. if you do not already have it, see the [dada2 installation instructions](https://benjjneb.github.io/dada2/dada-installation.html).

```{r}
library(dada2); packageVersion("dada2")
```


We set the path so that it points to the extracted directory of the dataset named "dog_samples" on your computer or cluster:

```{r}
MY_HOME <- Sys.getenv("HOME")
data <- paste(MY_HOME, "/dada2_tutorial_dog/dog_samples", sep='')  # change the path
list.files(data)
```


If your listed files match those here, you can start running the DADA2 pipeline.
<br/><br/>

Now, we read in the names of the fastq files and we sort them by forward and reverse. Then, we perform some string manipulation to extract a list of the sample names. 

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq and SAMPLENAME_R2.fastq
dataF <- sort(list.files(data, pattern="_R1.fastq", full.names = TRUE))
dataR <- sort(list.files(data, pattern="_R2.fastq", full.names = TRUE))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
list.sample.names <- sapply(strsplit(basename(dataF), "_"), `[`, 1)
list.sample.names
```

<br/><br/>

## <span style="color:green">1. Quality Control on the Raw Data</span>
The first step of the pipeline consists on visualizing the quality profiles of the dataset. 

Here, we visualize the quality profiles of the Forward reads:

```{r}
plotQualityProfile(dataF[1:3])
```

<br/><br/>

We visualize the quality profiles of the Reverse reads:

```{r}
plotQualityProfile(dataR[1:3])
```

<br/><br/>
Here, we have only the quality plot for three fastq files you can visualize more plots on the figure.

<br/><br/>

## <span style="color:green">2. Filter and Trim the Raw Data</span>
We assign the filenames for the filtered "_filt_fastq.gz" files under the filtered/ subdirectory:

```{r}
# Place filtered files in filtered/ subdirectory
filt.dataF <- file.path(data, "filtered", paste0(list.sample.names, "_F_filt.fastq.gz"))
filt.dataR <- file.path(data, "filtered", paste0(list.sample.names, "_R_filt.fastq.gz"))
names(filt.dataF) <- list.sample.names
names(filt.dataR) <- list.sample.names
```

For the filtering, we will use these parameters:
**maxN = 0** (DADA2 requeris no Ns), **truncQ=2**, **rm.phix=TRUE**, **maxEE=2** (it is the maximum number of expected errors allowed in a read), **truncLen(290, 275)** (it depends on the quality of your forward and reverse reads).

```{r}
out <- filterAndTrim(dataF, filt.dataF, dataR, filt.dataR, truncLen=c(290,275),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

This will take about 3 minutes to run.
<br/><br/>

## <span style="color:green">3. Learn the Error Rates</span>

The DADA2 pipeline uses the >b>learnErrors</b> method to learn the error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution.

We run the error rates on the Forward reads:
```{r}
errF <- learnErrors(filt.dataF, multithread=TRUE)
```

And on the Reverse reads:
```{r}
errR <- learnErrors(filt.dataR, multithread=TRUE)
```

Each command will take about 30 minutes to run.

Now, we can visualize the estimated error rates for the Forward reads:

```{r}
plotErrors(errF, nominalQ=TRUE)
```

We can visualize the estimated error rates for the Reverse reads:

```{r}
plotErrors(errR, nominalQ=TRUE)
```

<br/><br/>

## <span style="color:green">4. Sample Inference</span>

Now, we apply the <b> core sample inference algorithm</b> on the trimmed and filtered Forward and Reverse reads.

```{r}
dadaF <- dada(filt.dataF, err=errF, multithread=TRUE)
```

```{r}
dadaR <- dada(filt.dataR, err=errR, multithread=TRUE)
```

These steps make a dada-class object that can be visualized using the command below:
```{r}
dadaF[[1]]
```


<br/><br/>

## <span style="color:green">5. Merge the Paired Reads</span>

In this step, we merge the Forward and Reverse reads to obtain the full sequences.

```{r}
merge.reads <- mergePairs(dadaF, filt.dataF, dadaR, filt.dataR, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(merge.reads[[1]])
```

Then, we inspect the merger data.frame from the first sample.
```{r}
head(merge.reads[[1]])
```

<br/><br/>